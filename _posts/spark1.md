### spark

- 一种基于内存的快速、通用、可扩展的大数据分析计算引擎。

- spark和hadoop对比：这两个框架都是计算框架，随着技术的发展，都有庞大的生态圈。
  - hadoop:专用于批处理的数据处理框架，有存储和计算，核心也和计算相关。设计初衷是为了一次性数据计算。
  - spark：包含流处理的批处理框架，与hadoop不同的是，侧重于通过内存计算以及处理优化的机制快批处理的工作，加快运行速度，所以spark更快些。可以作为独立的集群来部署，也可以跟hadoop集群中并取代hadoop计算引擎。数据关联靠的是磁盘交互。这样磁盘的IO非常影响性能。(mapper->reducer)不满足循环迭代式的数据处理。并行运行的数据处理中，如机器学习，图形挖掘，交互式数据挖掘，计算的时候效率是非常低的。

- spark出现的时间相对比较晚，并且主要功能是用于数据计算，spark一直被认为是hadoop框架的升级版。

  - 一次性数据计算：框架在处理数据的时候，会从存储设备中读取数据，进行逻辑操作，然后将待处理的结果重新重新存储到介质中。
  
  - 提供了更加丰富的数据处理模型，而且可以基于内存来做数据集的多次迭代。这样更好支持数据挖掘和图像算法。优化了计算过程，改善了计算方式，保存在内存中，为下一次的计算提供了更加便利的处理方式，这种方式处理的效率就非常的高。
