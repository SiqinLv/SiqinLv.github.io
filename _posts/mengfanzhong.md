- 问答系统有：
  - Facebook开源的Blender系统，他具有个性人物聊天的功能，可以知识问答，是有史以来最大的开放域（Open-Domain）聊天机器人。
  - 还有Uber开源的Plato系统，也都具有比较完整的功能。
  - 框架完整性，可扩展性，易用性等各方面，RASA当仁不让是当前最全面的系统之一。
- Rasa为建立高效，灵活，专有的上下文对话机器人提供了必要的基础架构和工具。使用Rasa，任何人员都可以通过文本编辑器配置配置文件，就可以得到一个非常不错的对话机器人。
- RASA跟踪了最前沿的技术，并应用到系统中，保证了RASA的技术领先性。
- RASA的NLU为开发人员提供了解消息，确定意图并捕获关键上下文信息的技术。
- 支持多种语言，单一和多种意图，以及预训练和自定义实体等功能。RASA的CORE提供了多轮对话管理机制，使用Transformer技术自动学习上下文的与当前意图的关联性，而不是比较固定的状态机，再结合RulePolicy，提供了最大的灵活性。
- RASA也提供的非常好的扩展性
  - Tokenizer
  - Featurizer
  - Classifier
  - Policy
  - Action
  - 可以只使用RASA的pipeline框架
  - 可其他各个组件都自己定义
  - 使用Rasa-x工具可视化的配置机器人
  - RASA提供了一套从开发、测试到生产部署全套的解决方案
  - Conversation-Driven Development (CDD)一套方法论
  - Action Server
  - Rasa X
  - 支持Docker部署方式，简化生产运维等方式
  - ![image](https://user-images.githubusercontent.com/70061450/171103742-51bfa5fe-2424-4631-828f-4d3b0894c964.png)
- rasa处理一条用户消息的信息流向
  - ![image](https://user-images.githubusercontent.com/70061450/171107369-cfb881c1-f508-4cd1-9f3c-afa9f60b2415.png)
  - Dialogue Transformers是rasa工程师为多轮对话管理提供的一种思路
    - 使用Transform架构管理对话，把self-attention机制应用到每一轮对话序列上
    - 常见做法是使用层次RNN去编码多轮对话，这个假定了每轮对话都与完整序列相关，当当前对话有多个话题重叠时候，就会出现偏差。
    - 而transform架构，会通过selfattention机制，适当的忽略无关的历史上文，改进了RNN的缺陷。
- 在目前多轮对话有两种方法：
  + 第一种，Dialogue Stacks，这种模型认为子对话都存在于堆栈上，其中新主题到来时候引入到堆栈上，并且主题结束后就从堆栈中弹出，然后继续堆栈中的下一个主题。
    - 简单的理解，就是类似于函数调用，调用新函数时候，CPU将旧函数信息压入到堆栈，函数执行完成后，出栈
    - 缺点1：虽然堆栈自然允许处理和结束子对话，但堆栈的严格结构也有局限性。
    - 缺点2：RavenClaw的作者主张显式地跟踪主题，以支持用户意图的上下文解释。但是，一旦从对话堆栈中弹出一个主题，它就不能再提供此上下文。
    - 缺点3：如果主题已经从堆栈中弹出，这将不再有助于澄清用户想知道什么。
    > 在对话过程中，我们不能限制人们主题交错和重新介入的这些方式，因此我们需要一种比堆栈更灵活的架构
  + 第二种：使用RNN来处理多轮对话序列，我们期望，只要有足够的训练数据，RNN应该能够学习任何期望的行为。然而，在当前没有足够的语料库的情况下，并不能保证RNN可以学习生成这些行为。Vlasov等人和Sahay等人曾对RNN的基本结构进行修改，以将这种行为的归纳偏差纳入对话策略中，以此克服RNN的不适合对话建模的一个特性，RNN使用整个输入元素序列来生成编码，除非更复杂的结构（如长短期内存（LSTM））单元被训练到足够的数据上，以明确地知道它应该“忘记”序列的一部分。
  + 第三种：transform
    - transformer架构取代了RNN作为语言模型训练的标准，通过transformer XL和GPT-2等模型，在一系列语料上都实现了低困惑度，并产生了对各种下游任务有用的表示法。
    - transformer对意外输入（例如对抗性示例）更为稳健
    - 由于self-attention预先选择了哪些标记将对编码器的当前状态起作用，transformer可以忽略序列中不具信息性（或对抗性）的token
    - 为了在每个时间步进行预测，LSTM需要更新其内部内存单元，并将此更新传播到下一个时间步。如果当前时间步的输入是意外的，内部状态会受到干扰，在下一个时间步，神经网络会遇到一个与训练过程中遇到的任何情况都不同的记忆状态。
    - transformer通过self-attention机制来解释时间历程，使每个时间步的预测相互独立。如果一个变压器接收到一个不相关的输入，它可以忽略它，只使用以前的相关输入进行预测。
    - 由于transformer在每一步都选择序列中的哪些元素来产生编码器状态，我们假设它可能是处理对话历史的一个有用的架构。会话中的话语序列可能代表多个交错的话题，而transformer的self-attention可以同时学习如何理清这些话语片段，并做出适当的回应。
    - Transformers for open-domain dialogue
      - 这些架构可以在一个大型的、多样化的数据集上进行预先训练，然后针对特定领域中的面向任务的对话进行微调
      - Dinan等人使用了类似的方法，使用transformers对对话上下文以及背景知识进行编码，以研究基于开放域的对话。
        - 他们提出的体系结构有两种形式：
          - 一种是检索模型，transformers对通过排序选择的候选响应进行编码
          - 另一种是生成模型，其中使用一个transformers作为解码器，逐项生成响应
        - 我们的解决方案和这些方法的关键区别在于，我们在语篇层面上运用self-attention，关注的是对话的顺序，而不是单个回合中的标记序列。
  + Topic disentanglement in task-oriented dialogue
    - 最近的研究试图为对话策略生成神经网络结构，以此可以在单个会话中处理交错的语篇片段。Vlasov等人引入了递归嵌入对话策略（REDP）架构
    - REDP的ablation study强调REDP性能的提高是来源两方面，一个是对话历史上的注意机制，一个是从意外用户输入中恢复的复制机制。
    - 对标准RNN结构的这种修改使对话策略能够“跳过”对话历史中的特定回合，并在意外输入前后产生相同的编码器状态
    - 在不同注意力机制中，引入masking，提高有效性。在这项工作中，并没有扩充基本的RNN架构，而是用一个transformer取代它
    - 默认情况下，RNN处理序列中的每个项目以计算编码。REDP的修改是因为并非所有的对话历史都是相关的。基于这个原因，可以进一步用self-attention来代替RNN，不需要先验假设整个序列是相关的，而是对话策略应该选择哪些历史转折点，并选择相关响应。
  + Transformer Embeding Dialog（TED）Policy
    - 大大简化了REDP的体系结构
    - 与REDP类似，我们不使用分类器来选择系统操作。我们通过联合训练每个对话状态和每个系统动作的最大相似性
    - 在推理时，将对话的当前状态与所有可能的系统动作进行比较，选出相似度最高的一个。
    - 在任务型对话检索模型的训练中也采用了类似的方法。一个步骤由几个关键部分组成。
      - 特征化：策略将用户输入、系统动作和时隙特征化。
      - TED策略可以是端到端的，也可以是模块化的
      - 模块化方法类似于基于POMDP的对话策略或混合代码网络
      - 使用外部自然语言理解系统，用户输入被特征化为一个二进制向量，表示识别的意图和检测到的实体
      - 对话策略从一个固定的系统动作列表中预测一个动作。系统动作的特征是以二进制向量表示动作名称，遵循REDP方法
      - “端到端”的方法指的是对话序列之外没有监督。也就是说，NLU输出或系统动作名称没有黄金标签。TED是一个end-retrieval模型，它并不生成一个新的策略响应。
      - 在端到端的设置中，用户和系统的话语被编码为词袋向量。在对话的每一步，槽总是以二进制向量的形式来表示它们的存在、不存在或值对用户重不重要。我们使用一个简单的槽跟踪方法，用最近的值覆盖每个槽。
        - ![image](https://user-images.githubusercontent.com/70061450/171138988-b5ce42b7-f330-4173-bc8a-319b44b2fe2d.png)
      - Transformer的输入是用户输入和系统动作的序列。
      - 我们利用transformer中的self-attention机制，在每轮对话中，动态地访问历史对话的不同部分。对历史对话的关联性是从数据中学习出来的，并在每轮对话中重新计算。最重要的是，它允许对话策略在这一轮对话中考虑用户的话语，而在另一个轮对话中完全忽略它。
      - Similarity
        - ![image](https://user-images.githubusercontent.com/70061450/171139970-02208fc0-ecee-4350-a1b4-2f56fbb0cba5.png)
        - 一轮对话的损失函数来自于一个向量空间，这个空间是所有负采样的汇总和每一步的损失的平均值汇总到一轮对话上。
        - 总的损失函数就是，所有的每步对话的损失函数的平均值。
        - 在推理阶段，点积相似度就作为下一个对话的检索问题
        - 在模块化训练中，我们使用平衡批处理策略来减轻不同类别的不平衡，因为有些系统动作要比其他动作频繁得多。
        - 训练模型的训练对话量和测试集中每个动作都被正确预测的对话数
          - 同时满足我们两个标准的对话数据集是REDP数据集、MultiWOZ和Google Taskmaster-1,对于后者，我们必须从实体注释中提取操作标签，这并不总是可行。在我们的实验中，两个不同的模型作为基线。
          - Vlasov等人提出的REDP模型是专门为处理长期历史依赖而设计的，但它是基于LSTM的。
          - 另一个基于LSTM的策略与TED相同，只是transformer被LSTM替换了。

      
